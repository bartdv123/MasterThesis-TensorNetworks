{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for implementing DMRG tree structure optimization on tensor network level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the neccesary libraries and depedencies\n",
    "# First precompile takes more time -> Julia creates a underlying type-structure so that it can exploit the JIT feature\n",
    "using Plots\n",
    "using Makie\n",
    "using GraphMakie.NetworkLayout\n",
    "using CairoMakie\n",
    "using Tenet\n",
    "using TensorOperations\n",
    "using LinearAlgebra\n",
    "using Graphs\n",
    "using GraphPlot\n",
    "using EinExprs\n",
    "using Combinatorics\n",
    "using LaTeXStrings\n",
    "Makie.inline!(true)\n",
    "include(\"julia_functions.jl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a frucht graph TN, try to selected a cycle to transform into DMRG approachable tree\n",
    "\n",
    "dimension = 2\n",
    "G = Graphs.smallgraph(:frucht)\n",
    "tn1 = fill_with_random(G, dimension, false, true)\n",
    "locs_x =     [4, 4, -5, -2, 0, 0, 2, 0, -3, -1, -6, -4]\n",
    "locs_y = -1*[-2, 1, -2, -1, 0, -2, 0, 3, 3, 1, 1, 0]\n",
    "g, tensordict, edgesdict, fully_weighted_edge_list, edge_index_map = extract_graph_representation(tn1, false)\n",
    "\n",
    "drawing1 = Makie.plot(tn1, node_color=[:darkred for i in 1:length(tensors(tn1))], labels=true, layout=Stress(), edge_color=:grey80)\n",
    "display(drawing1)\n",
    "\n",
    "\n",
    "function replace_index(tensor, replace_inds, new_inds)\n",
    "    \n",
    "    mapping = Dict(zip(replace_inds, new_inds))\n",
    "    #display(mapping)\n",
    "    current_inds = inds(tensor)\n",
    "    ids = []\n",
    "    for id in current_inds\n",
    "        if id in replace_inds\n",
    "            push!(ids, mapping[id])\n",
    "        else\n",
    "            push!(ids, id)\n",
    "        end\n",
    "    end\n",
    "    new_tensor = Tenet.Tensor(tensor.data, [ids...])\n",
    "    return new_tensor\n",
    "end\n",
    "\n",
    "\n",
    "function extract_partial_tn_loop(TN, cycle)\n",
    "    tensors_in_loop = collect(Set([tensor for id in cycle for tensor in Tenet.select(TN, Symbol(id))])) #correct orderding of variable definitions\n",
    "    current_tn = TensorNetwork(tensor for tensor in tensors_in_loop)\n",
    "    #drawing1 = Makie.plot(current_tn, node_color=[:darkred for i in 1:length(tensors(current_tn))], labels=true, layout=Stress(), edge_color=:grey80)\n",
    "    #display(drawing1)\n",
    "    index_cut = Symbol(cycle[1])\n",
    "    edge_tensors = Tenet.select(TN, index_cut)\n",
    "\n",
    "    return current_tn\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function generate_unique_symbols(existing_indices::Vector{Symbol}, l::Int, min_value::Int=1, max_value::Int=200)\n",
    "\n",
    "    \"\"\"\n",
    "    Function which generates a list of new symbols for index replacing capability\n",
    "    \"\"\"\n",
    "\n",
    "    existing_integers = [parse(Int, string(id)) for id in existing_indices]\n",
    "    potential_length = round(Int, 4*l)  # Generate at least twice the desired length\n",
    "    new_symbols = []\n",
    "    for i in 1:potential_length\n",
    "        number = rand(min_value:max_value)\n",
    "        if !in(number, existing_integers)\n",
    "            if !in(number, new_symbols)\n",
    "                push!(new_symbols, number)\n",
    "            end\n",
    "        end\n",
    "        if length(new_symbols) == l\n",
    "            new_symbols = [Symbol(new) for new in new_symbols]\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "  \n",
    "    return new_symbols\n",
    "  \n",
    "end\n",
    "\n",
    "function collect_tensors_along_loop(loop_tn, start_tensor, end_tensor, index_cycle, edge_cut)\n",
    "\n",
    "    \"\"\"\n",
    "    Funtion whcih sequentially walks along the loop and selects the relevant tensors\n",
    "    \"\"\"\n",
    "\n",
    "    tensors_ordered_loop = []\n",
    "    index_cycle = filter(x -> x != edge_cut, index_cycle)\n",
    "    for i in 1:length(tensors(loop_tn))\n",
    "        if i == length(tensors(loop_tn))\n",
    "            push!(tensors_ordered_loop, end_tensor)\n",
    "            return tensors_ordered_loop\n",
    "        end\n",
    "        if i == 1\n",
    "            push!(tensors_ordered_loop, start_tensor)\n",
    "            continue\n",
    "        end\n",
    "        connecting_id = intersect(inds(tensors_ordered_loop[i-1]), [Symbol(id) for id in index_cycle])\n",
    "        next_tensor = [tensorc for tensorc in Tenet.select(loop_tn, connecting_id)  if tensorc != tensors_ordered_loop[i-1]][1]\n",
    "        index_cycle = filter(x -> x != parse(Int, string(connecting_id[1])), index_cycle)\n",
    "        push!(tensors_ordered_loop, next_tensor)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function create_index_isomorphismgroup(size_index1, size_index2, indices)\n",
    "    n = size_index1*size_index2\n",
    "    identity_data = Matrix{Int64}(I, n, n)\n",
    "    tensor_isomorphism = reshape(identity_data, (size_index1, size_index2, n))\n",
    "    #println(\"A grouping has been created: \", indices[1:2], \"==>\", indices[3])\n",
    "    identity_isomorphism = Tenet.Tensor(tensor_isomorphism, [(indices...)])\n",
    "    return identity_isomorphism\n",
    "end\n",
    "\n",
    "\n",
    "function create_index_isomorphismsplit(propagation_size, cut_size, new_indices, propagation_index)\n",
    "    size_id_to_tensor = convert(Int64, propagation_size/cut_size)\n",
    "    size_loop_part = cut_size\n",
    "    n = propagation_size\n",
    "    identity_data = Matrix{Int64}(I, n, n)\n",
    "    tensor_isomorphism = reshape(identity_data, (propagating_size, size_loop_part, size_id_to_tensor))\n",
    "    #println(\"A splitting has been created: \", propagation_index, \"==>\", new_indices[1:2])\n",
    "    identity_isomorphism = Tenet.Tensor(tensor_isomorphism, [propagating_index, new_indices...])\n",
    "    return identity_isomorphism\n",
    "end\n",
    "\n",
    "\n",
    "function transform_to_MPS(TN, edge_to_cut, index_cycle, printing=false)\n",
    "\n",
    "    \"\"\"\n",
    "    Function which takes in a tensor network, a cycle of indices\n",
    "    and an edge to cut, returns the MPS like structured TensorNetwork instead\n",
    "    of the loop TensorNetwork.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    inds_in_use = inds(TN)\n",
    "    loop_tn = extract_partial_tn_loop(TN, index_cycle)\n",
    "    n = length(tensors(loop_tn))\n",
    "    \n",
    "    # Generate an adequate amount of new indices to be used inside of the\n",
    "    # virtual tensor structure\n",
    "    new_inds = generate_unique_symbols(inds_in_use, 4*n-3)\n",
    "    start_tensor, end_tensor = Tenet.select(TN, Symbol(edge_to_cut))\n",
    "\n",
    "    #collect tensors along the loop from start_tensor to end_tensor\n",
    "    ordered_along_loop = collect_tensors_along_loop(loop_tn, start_tensor, end_tensor, deepcopy(index_cycle), edge_to_cut)\n",
    "    \n",
    "    # list for the new tensors inside of the tensor network\n",
    "    new_tn_tensors = []\n",
    "    global contract_list = []\n",
    "    global propagating_size\n",
    "    global cut_size\n",
    "    global propagating_index\n",
    "\n",
    "    # walk along the loop and make the necessary alterations at each step\n",
    "    for (i, tensor) in enumerate(ordered_along_loop)\n",
    "\n",
    "\n",
    "\n",
    "        # cases on the edges of the tensor network loop are treated seperately\n",
    "        if i == 1\n",
    "            # initial grouping and determine the cut_\n",
    "            # size of the index which is being collapsed\n",
    "\n",
    "            cut_size = size(tensor, Symbol(edge_to_cut))\n",
    "            new_virtual_inds = deepcopy(new_inds[1:3])\n",
    "            current_inds = inds(tensor)\n",
    "            dangling_leg = setdiff(inds(tensor), [Symbol(id) for id in index_cycle])\n",
    "            replace_leg = intersect(inds(tensor), [Symbol(id) for id in index_cycle])\n",
    "            iso = create_index_isomorphismgroup(size(tensor, replace_leg[1]), size(tensor, replace_leg[2]), new_virtual_inds)            \n",
    "            new_tensor = replace_index(tensor, replace_leg, new_virtual_inds[1:2])\n",
    "            contract_list = vcat(contract_list, new_virtual_inds[1:2])\n",
    "            push!(new_tn_tensors, new_tensor)\n",
    "\n",
    "            if printing == true\n",
    "                println(\"indices tensor $(i)\", inds(new_tensor), \"with sizes\", [size(new_tensor, id) for id in inds(new_tensor)])\n",
    "                println(\"indices identity_1:\", inds(iso), \"with sizes\", [size(iso, id) for id in inds(iso)])\n",
    "            end\n",
    "\n",
    "            push!(new_tn_tensors, iso)\n",
    "            propagating_index = inds(iso)[end]\n",
    "            propagating_size = size(iso, propagating_index)\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if i == length(ordered_along_loop)\n",
    "            \n",
    "            new_virtual_inds = deepcopy(new_inds[end-1:end])\n",
    "            current_inds = inds(tensor)\n",
    "            dangling_leg = setdiff(inds(tensor), [Symbol(id) for id in index_cycle])\n",
    "            replace_leg = intersect(inds(tensor), [Symbol(id) for id in index_cycle])\n",
    "            iso_inv = create_index_isomorphismsplit(propagating_size, cut_size, new_virtual_inds, propagating_index)\n",
    "            new_tensor = replace_index(tensor, replace_leg, new_virtual_inds)\n",
    "            if printing == true\n",
    "                println(\"indices identity_1_inv $(i-1)\", inds(iso_inv), \"with sizes\", [size(iso_inv, id) for id in inds(iso_inv)])\n",
    "                println(\"indices tensor $(i)\", inds(new_tensor), \"with sizes\", [size(new_tensor, id) for id in inds(new_tensor)])\n",
    "            end\n",
    "            contract_list = vcat(contract_list, new_virtual_inds[1:2])\n",
    "            push!(new_tn_tensors, new_tensor)\n",
    "            push!(new_tn_tensors, iso_inv)\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        # General \"bulk\" case\n",
    "        new_virtual_inds = new_inds[4+(i-2)*4:4+(i-1)*4-1]\n",
    "        iso_inv = create_index_isomorphismsplit(propagating_size, cut_size, [new_virtual_inds[1], new_virtual_inds[2]], propagating_index)\n",
    "        current_inds = inds(tensor)\n",
    "        dangling_leg = setdiff(inds(tensor), [Symbol(id) for id in index_cycle])\n",
    "        replace_leg = intersect(inds(tensor), [Symbol(id) for id in index_cycle])\n",
    "        new_tensor = replace_index(tensor, replace_leg, [new_virtual_inds[1], new_virtual_inds[3]])\n",
    "        iso = create_index_isomorphismgroup(cut_size, size(new_tensor, new_virtual_inds[3]), [new_virtual_inds[2], new_virtual_inds[3], new_virtual_inds[4]])\n",
    "        propagating_index = inds(iso)[end]\n",
    "        propagating_size = size(iso, propagating_index)\n",
    "\n",
    "        if printing == true\n",
    "            println(\"indices identity_1_inv $(i-1)\", inds(iso_inv), \"with sizes\", [size(iso_inv, id) for id in inds(iso_inv)])\n",
    "            println(\"indices tensor $(i)\", inds(new_tensor), \"with sizes\", [size(new_tensor, id) for id in inds(new_tensor)])\n",
    "            println(\"indices identity $(i)\", inds(iso), \"with sizes\", [size(iso, id) for id in inds(iso)])\n",
    "        end\n",
    "\n",
    "        contract_list = vcat(contract_list, new_virtual_inds[1:3])\n",
    "\n",
    "        push!(new_tn_tensors, iso_inv)\n",
    "        push!(new_tn_tensors, new_tensor)\n",
    "        push!(new_tn_tensors, iso)\n",
    "\n",
    "\n",
    "    end\n",
    "\n",
    "    return Tenet.TensorNetwork(new_tn_tensors), contract_list\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "example_cycle = [9, 8, 11]\n",
    "\n",
    "mps_network, contract_list = transform_to_MPS(tn1, example_cycle[1], example_cycle)\n",
    "loop_tn = extract_partial_tn_loop(tn1, example_cycle)\n",
    "drawing1 = Makie.plot(loop_tn, node_color=[:darkred for i in 1:length(tensors(loop_tn))], labels=true, layout=Stress(), edge_color=:grey80)\n",
    "display(drawing1)\n",
    "\n",
    "drawing1 = Makie.plot(mps_network, node_color=[:darkred for i in 1:length(tensors(mps_network))], labels=true, layout=Stress(), edge_color=:grey80)\n",
    "display(drawing1)\n",
    "\n",
    "\n",
    "\n",
    "for id in contract_list\n",
    "    #contracting two tensors contracts fully along all shared indices\n",
    "    # --> not everything in the list will be in the tensornetwork\n",
    "    if id ∈ inds(mps_network)\n",
    "        contraction_step(mps_network, [id])\n",
    "    end\n",
    "   \n",
    "end\n",
    "drawing1 = Makie.plot(mps_network, node_color=[:darkred for i in 1:length(tensors(mps_network))], labels=true, layout=Stress(), edge_color=:grey80)\n",
    "display(drawing1)\n",
    "\n",
    "### Comparing loop TN with MPS TN\n",
    "contract_list_loop = inds(loop_tn, :inner)\n",
    "\n",
    "\n",
    "for id in contract_list_loop\n",
    "    if id ∈ inds(loop_tn)\n",
    "        contraction_step(loop_tn, [id])\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "contract_list_MPS = inds(mps_network, :inner)\n",
    "\n",
    "for id in contract_list_MPS\n",
    "    if id ∈ inds(mps_network)\n",
    "        contraction_step(mps_network, [id])\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "t1 = tensors(loop_tn)[1]\n",
    "t2 = tensors(mps_network)[1]\n",
    "\n",
    "println(\"original loop contracted\")\n",
    "println(t1[1,1,1])\n",
    "println(\"mps representation contracted\")\n",
    "println(t2[1,1,1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function convert_TenetMPS_to_MPSkit(TenetMPS)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
